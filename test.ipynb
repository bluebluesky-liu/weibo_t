{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e197415b-3120-484b-81e7-cdc3145d2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jieba\n",
    "from torch import nn\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe1de17-c009-4a35-9eef-40074a741edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])  # 取序列的最后一个输出\n",
    "        return output\n",
    " \n",
    "# 数据读取\n",
    "def load_txt(path):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        data=[[line.strip()] for line in f.readlines()]\n",
    "        return data\n",
    " \n",
    "#去停用词\n",
    "def drop_stopword(datas):\n",
    "    # 假设你有一个函数用于预处理文本数据\n",
    "    with open('./hit_stopwords.txt', 'r', encoding='UTF8') as f:\n",
    "        stop_words = [word.strip() for word in f.readlines()]\n",
    "    datas=[x for x in datas if x not in stop_words]\n",
    "    return datas\n",
    " \n",
    "def preprocess_text(text):\n",
    "    text=list(jieba.cut(text))\n",
    "    text=drop_stopword(text)\n",
    "    return text\n",
    " \n",
    "# 将文本转换为Word2Vec向量表示\n",
    "def text_to_vector(text):\n",
    "    train_x = load_txt('train.txt')\n",
    "    test_x = load_txt('test.txt')\n",
    "    train = train_x + test_x\n",
    "    X_all = [i for x in train for i in x]\n",
    "    # 训练Word2Vec模型\n",
    "    word2vec_model = Word2Vec(sentences=X_all, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    vector = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv]\n",
    "    return sum(vector) / len(vector) if vector else [0] * word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e3f998-57ae-47ec-abe0-f0a45706cb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilig\\AppData\\Local\\Temp\\ipykernel_24536\\1263557569.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_text:哥哥太帅啦~\n",
      "模型预测的类别: 正面情绪\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    #input_text = \"什么破活动，没有空调人还多，大夏天热死了\"\n",
    "    input_text = \"哥哥太帅啦~\"\n",
    "    label = {1: \"正面情绪\", 0: \"负面情绪\"}\n",
    "    model = torch.load('model.pth')\n",
    "    # 预处理输入数据\n",
    "    input_data = preprocess_text(input_text)\n",
    "    # 确保输入词向量与模型维度和数据类型相同\n",
    "    input_data=[[text_to_vector(input_data)]]\n",
    "    input_arry= np.array(input_data, dtype=np.float32)\n",
    "    input_tensor = torch.Tensor(input_arry)\n",
    "    # 将输入数据传入模型\n",
    "    with torch.no_grad():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        output = model(input_tensor)\n",
    "    # 这里只一个简单的示例\n",
    "    predicted_class = label[torch.argmax(output).item()]\n",
    "    print(f\"predicted_text:{input_text}\")\n",
    "    print(f\"模型预测的类别: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d56da-c03f-4cc5-b3e9-5290aa13f415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
